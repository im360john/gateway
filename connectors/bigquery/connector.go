package bigquery

import (
	"context"
	_ "embed"
	"fmt"
	"os"
	"path/filepath"
	"strings"

	"cloud.google.com/go/bigquery"
	"github.com/centralmind/gateway/castx"
	"github.com/centralmind/gateway/connectors"
	"github.com/centralmind/gateway/logger"
	"github.com/centralmind/gateway/model"
	"golang.org/x/xerrors"
	"google.golang.org/api/iterator"
	"google.golang.org/api/option"
)

//go:embed readme.md
var docString string

func init() {
	connectors.Register(func(cfg Config) (connectors.Connector, error) {
		var opts []option.ClientOption

		if cfg.Credentials != "" && cfg.Credentials != "{}" {
			credentialsFile := filepath.Join(logger.DefaultLogDir(), "bigquery-credentials.json")
			if err := os.WriteFile(credentialsFile, []byte(cfg.Credentials), 0600); err != nil {
				return nil, xerrors.Errorf("unable to write credentials file: %w", err)
			}
			opts = append(opts, option.WithCredentialsFile(credentialsFile))
		}

		if cfg.Endpoint != "" {
			opts = append(
				opts,
				option.WithEndpoint(cfg.Endpoint),
				option.WithoutAuthentication(),
			)
		}

		ctx := context.Background()
		client, err := bigquery.NewClient(ctx, cfg.ProjectID, opts...)
		if err != nil {
			return nil, xerrors.Errorf("failed to create client: %w", err)
		}

		return &Connector{
			config: cfg,
			client: client,
		}, nil
	})
}

type Config struct {
	ProjectID   string `json:"project_id" yaml:"project_id"`
	Dataset     string `json:"dataset" yaml:"dataset"`
	Credentials string `json:"credentials" yaml:"credentials"`
	Endpoint    string `yaml:"endpoint"`
}

func (c Config) ExtraPrompt() []string {
	return []string{
		"Do not include limit / offset as parameters",
	}
}

func (c Config) Type() string {
	return "bigquery"
}

func (c Config) Doc() string {
	return docString
}

type Connector struct {
	config Config
	client *bigquery.Client
}

func (c *Connector) Config() connectors.Config {
	return c.config
}

func (c *Connector) Sample(ctx context.Context, table model.Table) ([]map[string]any, error) {
	q := c.client.Query(fmt.Sprintf("SELECT * FROM `%s.%s.%s` LIMIT 5",
		c.config.ProjectID, c.config.Dataset, table.Name))

	it, err := q.Read(ctx)
	if err != nil {
		return nil, xerrors.Errorf("error executing query: %w", err)
	}

	var results []map[string]any
	for {
		var row map[string]bigquery.Value
		err := it.Next(&row)
		if err == iterator.Done {
			break
		}
		if err != nil {
			return nil, xerrors.Errorf("error reading row: %w", err)
		}

		// Convert bigquery.Value to regular interface{}
		converted := make(map[string]interface{})
		for k, v := range row {
			converted[k] = v
		}
		results = append(results, converted)
	}

	return results, nil
}

func (c *Connector) Discovery(ctx context.Context) ([]model.Table, error) {
	ds := c.client.Dataset(c.config.Dataset)

	// Get list of tables
	it := ds.Tables(ctx)

	var tables []model.Table
	for {
		tbl, err := it.Next()
		if err == iterator.Done {
			break
		}
		if err != nil {
			return nil, xerrors.Errorf("error iterating tables: %w", err)
		}

		// Get table metadata
		md, err := tbl.Metadata(ctx)
		if err != nil {
			return nil, xerrors.Errorf("error getting table metadata: %w", err)
		}

		columns := make([]model.ColumnSchema, len(md.Schema))
		for i, field := range md.Schema {
			columns[i] = model.ColumnSchema{
				Name:       field.Name,
				Type:       c.GuessColumnType(string(field.Type)),
				PrimaryKey: false,
			}
		}

		// Get row count
		q := c.client.Query(fmt.Sprintf("SELECT COUNT(*) as count FROM `%s.%s.%s`",
			c.config.ProjectID, c.config.Dataset, tbl.TableID))

		it, err := q.Read(ctx)
		if err != nil {
			return nil, xerrors.Errorf("error executing query: %w", err)
		}

		var row struct{ Count int64 }
		err = it.Next(&row)
		if err != nil {
			return nil, xerrors.Errorf("error getting row count: %w", err)
		}

		tables = append(tables, model.Table{
			Name:     tbl.TableID,
			Columns:  columns,
			RowCount: int(row.Count),
		})
	}

	return tables, nil
}

func (c *Connector) Ping(ctx context.Context) error {
	// Simple metadata call to check connection
	_, err := c.client.Dataset(c.config.Dataset).Metadata(ctx)
	return err
}

func (c *Connector) Query(ctx context.Context, endpoint model.Endpoint, params map[string]any) ([]map[string]any, error) {
	processed, err := castx.ParamsE(endpoint, params)
	if err != nil {
		return nil, xerrors.Errorf("unable to process params: %w", err)
	}
	for name, value := range processed {
		if name == "offset" || name == "limit" { // these 2 are special
			endpoint.Query = strings.ReplaceAll(endpoint.Query, "@"+name, fmt.Sprintf("%v", value))
		}
	}

	// Create query with parameters
	q := c.client.Query(endpoint.Query)

	// Set query parameters
	for name, value := range processed {
		if name == "offset" || name == "limit" { // these 2 are special
			continue
		}
		q.Parameters = append(q.Parameters, bigquery.QueryParameter{
			Name:  name,
			Value: value,
		})
	}

	// Run query
	it, err := q.Read(ctx)
	if err != nil {
		return nil, xerrors.Errorf("error executing query: %w", err)
	}

	var results []map[string]any
	for {
		var row map[string]bigquery.Value
		err := it.Next(&row)
		if err == iterator.Done {
			break
		}
		if err != nil {
			return nil, xerrors.Errorf("error reading row: %w", err)
		}

		// Convert bigquery.Value to regular interface{}
		converted := make(map[string]interface{})
		for k, v := range row {
			converted[k] = v
		}
		results = append(results, converted)
	}

	return results, nil
}

func (c *Connector) GuessColumnType(sqlType string) model.ColumnType {
	switch sqlType {
	case "STRING", "BYTES":
		return model.TypeString
	case "INTEGER", "INT64":
		return model.TypeInteger
	case "FLOAT", "FLOAT64", "NUMERIC", "BIGNUMERIC":
		return model.TypeNumber
	case "BOOLEAN", "BOOL":
		return model.TypeBoolean
	case "TIMESTAMP", "DATE", "TIME", "DATETIME":
		return model.TypeDatetime
	case "RECORD", "STRUCT":
		return model.TypeObject
	case "ARRAY":
		return model.TypeArray
	default:
		return model.TypeString
	}
}

func (c *Connector) InferResultColumns(ctx context.Context, query string) ([]model.ColumnSchema, error) {
	// Create a dry run job to get schema without executing the query
	query = strings.ReplaceAll(query, "@limit", "1")
	query = strings.ReplaceAll(query, "@offset", "0")
	if !strings.HasPrefix(strings.ToLower(query), "select") {
		return nil, nil
	}
	q := c.client.Query(query)
	q.DryRun = true

	job, err := q.Run(ctx)
	if err != nil {
		return nil, xerrors.Errorf("error in dry run: %w", err)
	}

	status := job.LastStatus()
	if status.Statistics == nil || status.Statistics.Details == nil {
		return nil, xerrors.New("no schema information available")
	}

	details, ok := status.Statistics.Details.(*bigquery.QueryStatistics)
	if !ok {
		return nil, xerrors.New("unexpected statistics type")
	}

	if details.Schema == nil {
		return nil, xerrors.New("no schema information available")
	}

	columns := make([]model.ColumnSchema, 0)
	for _, field := range details.Schema {
		columns = append(columns, model.ColumnSchema{
			Name: field.Name,
			Type: c.GuessColumnType(string(field.Type)),
		})
	}

	return columns, nil
}

func (c *Connector) InferQuery(ctx context.Context, query string) ([]model.ColumnSchema, error) {
	return c.InferResultColumns(ctx, query)
}

// Close releases any resources held by the connector
func (c *Connector) Close() error {
	return c.client.Close()
}
